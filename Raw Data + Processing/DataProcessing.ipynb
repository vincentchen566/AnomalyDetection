{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c078699d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import tqdm\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17e34e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the \"data\" containing too much signal\n",
    "features=pd.read_hdf(\"events_anomalydetection_v2.features.h5\")\n",
    "\n",
    "# additionally produced bkg\n",
    "features_extrabkg = pd.read_hdf(\"events_anomalydetection_qcd_extra_inneronly_features.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "861a39a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## to be split among the different sets \n",
    "features_extrabkg1 = features_extrabkg[:312858]\n",
    "\n",
    "## to be used to enhance the evalaution\n",
    "features_extrabkg2 = features_extrabkg[312858:]\n",
    "\n",
    "features_sig=features[features['label']==1]\n",
    "features_bg=features[features['label']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65d90cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(features_bg[['mj1','mj2']]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83cc440d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.keys of                pxj1         pyj1         pzj1         mj1      tau1j1  \\\n",
      "0      -1467.239990   611.502014   511.101990   38.896000    8.290660   \n",
      "1      -1211.239990   347.315002   547.963013  389.532013  191.804001   \n",
      "2      -1229.619995   649.857971     8.089170   72.155502   47.168098   \n",
      "3       -693.304016 -1046.729980  1716.910034   55.797798   24.788601   \n",
      "4      -1488.199951   -25.370100   -30.989700   84.891502   26.878799   \n",
      "...             ...          ...          ...         ...         ...   \n",
      "999995  -286.550995 -1310.829956 -1510.910034  147.516998   60.997799   \n",
      "999996   918.562988   951.195984 -1622.569946   32.242199    5.894100   \n",
      "999997  1447.219971  -547.710999   827.945007  396.112000  181.406998   \n",
      "999998   200.035995 -1252.869995    27.924900  363.790985  139.281998   \n",
      "999999  -811.379028  1050.810059     5.019200  150.214996   92.509003   \n",
      "\n",
      "            tau2j1     tau3j1         pxj2         pyj2         pzj2  \\\n",
      "0         4.836080   4.260190  1403.579956  -674.551025  -451.670990   \n",
      "1        99.562798  70.872200   619.341003   -62.177299 -1944.040039   \n",
      "2        37.243198  33.658199  1196.250000  -647.896973 -1283.109985   \n",
      "3         6.890150   5.813390   747.961975   994.250000  -412.966003   \n",
      "4        15.517200  13.260400  1415.640015    20.905100   223.630997   \n",
      "...            ...        ...          ...          ...          ...   \n",
      "999995   41.356201  28.225700   252.884995  1085.420044   759.314026   \n",
      "999996    5.004090   3.992730  -266.285004 -1284.189941   185.007996   \n",
      "999997  152.207993  86.676804  -932.369995   165.005005 -2806.959961   \n",
      "999998   31.751499  22.884300  -583.494995  1096.890015 -1194.410034   \n",
      "999999   84.807404  60.520599   778.544983 -1053.369995  1374.719971   \n",
      "\n",
      "               mj2      tau1j2      tau2j2     tau3j2  label  \n",
      "0       237.893997   79.815102   21.010300  16.757601    0.0  \n",
      "1        22.999201    8.042190    6.335090   5.525360    0.0  \n",
      "2        78.230698   15.292900   13.944200  10.013500    0.0  \n",
      "3       359.113007  175.209000  103.500999  84.447098    0.0  \n",
      "4        77.506500   57.986000   34.147400  26.660601    0.0  \n",
      "...            ...         ...         ...        ...    ...  \n",
      "999995   58.769901   42.276402    8.637120   7.852020    0.0  \n",
      "999996  136.389008   70.623802   49.508499  40.708599    0.0  \n",
      "999997   56.471600   14.446400   10.258900   8.874690    0.0  \n",
      "999998  105.186996   36.687000   23.652201  19.462601    0.0  \n",
      "999999   49.620399   17.338499   11.030100   9.865980    0.0  \n",
      "\n",
      "[1000000 rows x 15 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(features_bg.keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1990765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from data\n",
    "jet1_bg = np.array(features_bg[['pxj1', 'pyj1','pzj1']])\n",
    "jet2_bg = np.array(features_bg[['pxj2','pyj2','pzj2']])\n",
    "mj1mj2_bg = np.array(features_bg[['mj1','mj2']])\n",
    "tau21_bg = np.array(features_bg[['tau2j1','tau2j2']])/(1e-5+np.array(features_bg[['tau1j1','tau1j2']]))\n",
    "tau32_bg = np.array(features_bg[['tau3j1','tau3j2']])/(1e-5+np.array(features_bg[['tau2j1','tau2j2']]))\n",
    "\n",
    "jet1_sig = np.array(features_sig[['pxj1', 'pyj1','pzj1']])\n",
    "jet2_sig = np.array(features_sig[['pxj2','pyj2','pzj2']])\n",
    "mj1mj2_sig = np.array(features_sig[['mj1','mj2']])\n",
    "tau21_sig = np.array(features_sig[['tau2j1','tau2j2']])/(1e-5+np.array(features_sig[['tau1j1','tau1j2']]))\n",
    "tau32_sig = np.array(features_sig[['tau3j1','tau3j2']])/(1e-5+np.array(features_sig[['tau2j1','tau2j2']]))\n",
    "\n",
    "\n",
    "jet1_extrabkg1 = np.array(features_extrabkg1[['pxj1', 'pyj1','pzj1']])\n",
    "jet2_extrabkg1 = np.array(features_extrabkg1[['pxj2','pyj2','pzj2']])\n",
    "mj1mj2_extrabkg1 = np.array(features_extrabkg1[['mj1','mj2']])\n",
    "tau21_extrabkg1 = np.array(features_extrabkg1[['tau2j1','tau2j2']])/(1e-5+np.array(features_extrabkg1[['tau1j1','tau1j2']]))\n",
    "tau32_extrabkg1 = np.array(features_extrabkg1[['tau3j1','tau3j2']])/(1e-5+np.array(features_extrabkg1[['tau2j1','tau2j2']]))\n",
    "\n",
    "jet1_extrabkg2 = np.array(features_extrabkg2[['pxj1', 'pyj1','pzj1']])\n",
    "jet2_extrabkg2 = np.array(features_extrabkg2[['pxj2','pyj2','pzj2']])\n",
    "mj1mj2_extrabkg2 = np.array(features_extrabkg2[['mj1','mj2']])\n",
    "tau21_extrabkg2 = np.array(features_extrabkg2[['tau2j1','tau2j2']])/(1e-5+np.array(features_extrabkg2[['tau1j1','tau1j2']]))\n",
    "tau32_extrabkg2 = np.array(features_extrabkg2[['tau3j1','tau3j2']])/(1e-5+np.array(features_extrabkg2[['tau2j1','tau2j2']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "922dd34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting of mj1 and mj2:\n",
    "# Identifies which column has the minimum of mj1 and mj2, and sorts it so the new array mjmin contains the \n",
    "# mj with the smallest energy, and mjmax is the one with the biggest.\n",
    "mjmin_bg = mj1mj2_bg[range(len(mj1mj2_bg)), np.argmin(mj1mj2_bg, axis=1)] \n",
    "mjmax_bg = mj1mj2_bg[range(len(mj1mj2_bg)), np.argmax(mj1mj2_bg, axis=1)]\n",
    "mjmin_sig = mj1mj2_sig[range(len(mj1mj2_sig)), np.argmin(mj1mj2_sig, axis=1)]\n",
    "mjmax_sig = mj1mj2_sig[range(len(mj1mj2_sig)), np.argmax(mj1mj2_sig, axis=1)]\n",
    "mjmin_extrabkg1 = mj1mj2_extrabkg1[range(len(mj1mj2_extrabkg1)), np.argmin(mj1mj2_extrabkg1, axis=1)] \n",
    "mjmax_extrabkg1 = mj1mj2_extrabkg1[range(len(mj1mj2_extrabkg1)), np.argmax(mj1mj2_extrabkg1, axis=1)]\n",
    "mjmin_extrabkg2 = mj1mj2_extrabkg2[range(len(mj1mj2_extrabkg2)), np.argmin(mj1mj2_extrabkg2, axis=1)] \n",
    "mjmax_extrabkg2 = mj1mj2_extrabkg2[range(len(mj1mj2_extrabkg2)), np.argmax(mj1mj2_extrabkg2, axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0153727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we do the same sorting for the taus\n",
    "tau21min_bg=tau21_bg[range(len(mj1mj2_bg)), np.argmin(mj1mj2_bg, axis=1)]\n",
    "tau21max_bg=tau21_bg[range(len(mj1mj2_bg)), np.argmax(mj1mj2_bg, axis=1)]\n",
    "tau21min_sig=tau21_sig[range(len(mj1mj2_sig)), np.argmin(mj1mj2_sig, axis=1)]\n",
    "tau21max_sig=tau21_sig[range(len(mj1mj2_sig)), np.argmax(mj1mj2_sig, axis=1)]\n",
    "tau21min_extrabkg1 = tau21_extrabkg1[range(len(mj1mj2_extrabkg1)), np.argmin(mj1mj2_extrabkg1, axis=1)]\n",
    "tau21max_extrabkg1 = tau21_extrabkg1[range(len(mj1mj2_extrabkg1)), np.argmax(mj1mj2_extrabkg1, axis=1)]\n",
    "tau21min_extrabkg2 = tau21_extrabkg2[range(len(mj1mj2_extrabkg2)), np.argmin(mj1mj2_extrabkg2, axis=1)]\n",
    "tau21max_extrabkg2 = tau21_extrabkg2[range(len(mj1mj2_extrabkg2)), np.argmax(mj1mj2_extrabkg2, axis=1)]\n",
    "\n",
    "tau32min_bg=tau32_bg[range(len(mj1mj2_bg)), np.argmin(mj1mj2_bg, axis=1)]\n",
    "tau32max_bg=tau32_bg[range(len(mj1mj2_bg)), np.argmax(mj1mj2_bg, axis=1)]\n",
    "tau32min_sig=tau32_sig[range(len(mj1mj2_sig)), np.argmin(mj1mj2_sig, axis=1)]\n",
    "tau32max_sig=tau32_sig[range(len(mj1mj2_sig)), np.argmax(mj1mj2_sig, axis=1)]\n",
    "tau32min_extrabkg1 = tau32_extrabkg1[range(len(mj1mj2_extrabkg1)), np.argmin(mj1mj2_extrabkg1, axis=1)]\n",
    "tau32max_extrabkg1 = tau32_extrabkg1[range(len(mj1mj2_extrabkg1)), np.argmax(mj1mj2_extrabkg1, axis=1)]\n",
    "tau32min_extrabkg2 = tau32_extrabkg2[range(len(mj1mj2_extrabkg2)), np.argmin(mj1mj2_extrabkg2, axis=1)]\n",
    "tau32max_extrabkg2 = tau32_extrabkg2[range(len(mj1mj2_extrabkg2)), np.argmax(mj1mj2_extrabkg2, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05ee3c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mjj and collect the features into a dataset, plus mark signal/bg with 1/0\n",
    "pjj_sig = (np.array(features_sig[['pxj1','pyj1','pzj1']])+np.array(features_sig[['pxj2','pyj2','pzj2']]))\n",
    "Ejj_sig = np.sqrt(np.sum(np.array(features_sig[['pxj1','pyj1','pzj1','mj1']])**2, axis=1))\\\n",
    "    +np.sqrt(np.sum(np.array(features_sig[['pxj2','pyj2','pzj2','mj2']])**2, axis=1))\n",
    "mjj_sig = np.sqrt(Ejj_sig**2-np.sum(pjj_sig**2, axis=1))\n",
    "\n",
    "pjj_bg = (np.array(features_bg[['pxj1','pyj1','pzj1']])+np.array(features_bg[['pxj2','pyj2','pzj2']]))\n",
    "Ejj_bg = np.sqrt(np.sum(np.array(features_bg[['pxj1','pyj1','pzj1','mj1']])**2, axis=1))\\\n",
    "    +np.sqrt(np.sum(np.array(features_bg[['pxj2','pyj2','pzj2','mj2']])**2, axis=1))\n",
    "mjj_bg = np.sqrt(Ejj_bg**2-np.sum(pjj_bg**2, axis=1))\n",
    "\n",
    "pjj_extrabkg1 = (np.array(features_extrabkg1[['pxj1','pyj1','pzj1']])+np.array(features_extrabkg1[['pxj2','pyj2','pzj2']]))\n",
    "Ejj_extrabkg1 = np.sqrt(np.sum(np.array(features_extrabkg1[['pxj1','pyj1','pzj1','mj1']])**2, axis=1))\\\n",
    "    +np.sqrt(np.sum(np.array(features_extrabkg1[['pxj2','pyj2','pzj2','mj2']])**2, axis=1))\n",
    "mjj_extrabkg1 = np.sqrt(Ejj_extrabkg1**2-np.sum(pjj_extrabkg1**2, axis=1))\n",
    "pjj_extrabkg2 = (np.array(features_extrabkg2[['pxj1','pyj1','pzj1']])+np.array(features_extrabkg2[['pxj2','pyj2','pzj2']]))\n",
    "Ejj_extrabkg2 = np.sqrt(np.sum(np.array(features_extrabkg2[['pxj1','pyj1','pzj1','mj1']])**2, axis=1))\\\n",
    "    +np.sqrt(np.sum(np.array(features_extrabkg2[['pxj2','pyj2','pzj2','mj2']])**2, axis=1))\n",
    "mjj_extrabkg2 = np.sqrt(Ejj_extrabkg2**2-np.sum(pjj_extrabkg2**2, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a244c2",
   "metadata": {},
   "source": [
    "# ORDER OF THINGS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa1fef5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000,)\n",
      "(1000000, 3)\n",
      "(1, 1000000, 8)\n"
     ]
    }
   ],
   "source": [
    "print(mjj_bg.shape)\n",
    "print(jet1_bg.shape)\n",
    "\n",
    "dataset_bg = np.dstack((mjj_bg/1000,  mjmin_bg/1000, (mjmax_bg-mjmin_bg)/1000, tau21min_bg, tau21max_bg, tau32min_bg, tau32max_bg, np.zeros(len(mjj_bg))))\n",
    "print(dataset_bg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09301bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##ORDER OF THINGS\n",
    "dataset_bg = np.dstack((mjj_bg/1000, mjmin_bg/1000, (mjmax_bg-mjmin_bg)/1000, tau21min_bg, tau21max_bg, tau32min_bg, tau32max_bg, np.zeros(len(mjj_bg))))[0]\n",
    "dataset_bg = np.hstack((jet1_bg, jet2_bg, dataset_bg))\n",
    "\n",
    "dataset_sig = np.dstack((mjj_sig/1000, mjmin_sig/1000, (mjmax_sig-mjmin_sig)/1000, tau21min_sig, tau21max_sig, tau32min_sig, tau32max_sig, np.ones(len(mjj_sig))))[0]\n",
    "dataset_sig = np.hstack((jet1_sig, jet2_sig, dataset_sig))\n",
    "\n",
    "dataset_extrabkg1 = np.dstack((mjj_extrabkg1/1000, mjmin_extrabkg1/1000, (mjmax_extrabkg1-mjmin_extrabkg1)/1000, tau21min_extrabkg1, tau21max_extrabkg1, tau32min_extrabkg1, tau32max_extrabkg1, np.zeros(len(mjj_extrabkg1))))[0]\n",
    "dataset_extrabkg1 = np.hstack((jet1_extrabkg1, jet2_extrabkg1, dataset_extrabkg1))\n",
    "\n",
    "dataset_extrabkg2 = np.dstack((mjj_extrabkg2/1000, mjmin_extrabkg2/1000, (mjmax_extrabkg2-mjmin_extrabkg2)/1000, tau21min_extrabkg2, tau21max_extrabkg2, tau32min_extrabkg2, tau32max_extrabkg2, np.zeros(len(mjj_extrabkg2))))[0]\n",
    "dataset_extrabkg2 = np.hstack((jet1_extrabkg2, jet2_extrabkg2, dataset_extrabkg2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d3c2d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.seed(args.seed) # Set the random seed so we get a deterministic result\n",
    "\n",
    "np.random.shuffle(dataset_sig)\n",
    "\n",
    "n_sig = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "932292ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = np.concatenate((dataset_bg, dataset_sig[:n_sig]))\n",
    "indices = np.array(range(len(data_all))).astype('int')\n",
    "np.random.shuffle(indices)\n",
    "data_all = data_all[indices]\n",
    "indices_extrabkg1 = np.array(range(len(dataset_extrabkg1))).astype('int')\n",
    "np.random.shuffle(indices_extrabkg1)\n",
    "dataset_extrabkg1 = dataset_extrabkg1[indices_extrabkg1]\n",
    "indices_extrabkg2 = np.array(range(len(dataset_extrabkg2))).astype('int')\n",
    "np.random.shuffle(indices_extrabkg2)\n",
    "dataset_extrabkg2 = dataset_extrabkg2[indices_extrabkg2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2896aec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format of data_all: mjj (TeV), mjmin (TeV), mjmax-mjmin (TeV), tau21(mjmin), tau21 (mjmax), tau32(mjmin), tau32 (mjmax), sigorbg label\n",
    "\n",
    "minmass=3.3\n",
    "maxmass=3.7\n",
    "\n",
    "innermask = (data_all[:,0]>minmass) & (data_all[:,0]<maxmass)\n",
    "outermask = ~innermask\n",
    "innerdata = data_all[innermask]\n",
    "outerdata = data_all[outermask]\n",
    "\n",
    "innermask_extrabkg1 = (dataset_extrabkg1[:,0]>minmass) & (dataset_extrabkg1[:,0]<maxmass)\n",
    "innerdata_extrabkg1 = dataset_extrabkg1[innermask_extrabkg1]\n",
    "innermask_extrabkg2 = (dataset_extrabkg2[:,0]>minmass) & (dataset_extrabkg2[:,0]<maxmass)\n",
    "innerdata_extrabkg2 = dataset_extrabkg2[innermask_extrabkg2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bf5d285",
   "metadata": {},
   "outputs": [],
   "source": [
    "outerdata_train = outerdata[:500000]\n",
    "outerdata_val = outerdata[500000:]\n",
    "\n",
    "innerdata_train = innerdata[:60000]\n",
    "innerdata_val = innerdata[60000:120000]\n",
    "\n",
    "innerdata_extrasig = dataset_sig[n_sig:]\n",
    "innerdata_extrasig = innerdata_extrasig[(innerdata_extrasig[:,0]>minmass) & (innerdata_extrasig[:,0]<maxmass)]\n",
    "\n",
    "## splitting extra signal into train, val and test set\n",
    "n_sig_test = 20000\n",
    "n_extrasig_train =  (innerdata_extrasig.shape[0]-n_sig_test)//2\n",
    "innerdata_extrasig_test = innerdata_extrasig[:n_sig_test]\n",
    "innerdata_extrasig_train = innerdata_extrasig[n_sig_test:n_sig_test+n_extrasig_train]\n",
    "innerdata_extrasig_val = innerdata_extrasig[n_sig_test+n_extrasig_train:]\n",
    "\n",
    "## splitting extra bkg (1) into train, val and test set\n",
    "n_bkg_test = 40000\n",
    "n_extrabkg_train =  (innerdata_extrabkg1.shape[0]-n_bkg_test)//2\n",
    "innerdata_extrabkg1_test = innerdata_extrabkg1[:n_bkg_test]\n",
    "innerdata_extrabkg1_train = innerdata_extrabkg1[n_bkg_test:n_bkg_test+n_extrabkg_train]\n",
    "innerdata_extrabkg1_val = innerdata_extrabkg1[n_bkg_test+n_extrabkg_train:]\n",
    "\n",
    "## putting together artificial test set\n",
    "innerdata_test = np.vstack((innerdata_extrabkg1_test, innerdata_extrasig_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09760f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('outerdata_train_6var.npy', outerdata_train)\n",
    "np.save('outerdata_test_6var.npy', outerdata_val)\n",
    "np.save('innerdata_train_6var.npy', innerdata_train)\n",
    "np.save('innerdata_val_6var.npy', innerdata_val)   \n",
    "np.save('innerdata_test_6var.npy', innerdata_test)      \n",
    "np.save('innerdata_extrasig_train_6var.npy', innerdata_extrasig_train)\n",
    "np.save('innerdata_extrasig_val_6var.npy', innerdata_extrasig_val)\n",
    "np.save('innerdata_extrabkg_train_6var.npy', innerdata_extrabkg1_train)\n",
    "np.save('innerdata_extrabkg_val_6var.npy', innerdata_extrabkg1_val)\n",
    "np.save('innerdata_extrabkg_test_6var.npy', innerdata_extrabkg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d20d789",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6536b34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['axis0', 'axis1', 'block0_items', 'block0_values']>\n"
     ]
    }
   ],
   "source": [
    "print(f1['df'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34bdae35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"axis0\": shape (15,), type \"|S6\">\n",
      "<HDF5 dataset \"axis1\": shape (1100000,), type \"<i8\">\n",
      "<HDF5 dataset \"block0_items\": shape (15,), type \"|S6\">\n",
      "<HDF5 dataset \"block0_values\": shape (1100000, 15), type \"<f8\">\n"
     ]
    }
   ],
   "source": [
    "for key in [\"axis0\", 'axis1' , 'block0_items', 'block0_values']:\n",
    "    print(f1['df'][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6eac711d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'pxj1'\n",
      "b'pyj1'\n",
      "b'pzj1'\n",
      "b'mj1'\n",
      "b'tau1j1'\n",
      "b'tau2j1'\n",
      "b'tau3j1'\n",
      "b'pxj2'\n",
      "b'pyj2'\n",
      "b'pzj2'\n",
      "b'mj2'\n",
      "b'tau1j2'\n",
      "b'tau2j2'\n",
      "b'tau3j2'\n",
      "b'label'\n"
     ]
    }
   ],
   "source": [
    "for i in range(15):\n",
    "    print(f1['df']['axis0'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c88168bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'pxj1'\n",
      "b'pyj1'\n",
      "b'pzj1'\n",
      "b'mj1'\n",
      "b'tau1j1'\n",
      "b'tau2j1'\n",
      "b'tau3j1'\n",
      "b'pxj2'\n",
      "b'pyj2'\n",
      "b'pzj2'\n",
      "b'mj2'\n",
      "b'tau1j2'\n",
      "b'tau2j2'\n",
      "b'tau3j2'\n",
      "b'label'\n"
     ]
    }
   ],
   "source": [
    "for i in range(15):\n",
    "    print(f1['df']['block0_items'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78fc3996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2101)\n",
      "Memory in GB: 0.15661120414733887\n"
     ]
    }
   ],
   "source": [
    "df_test = pandas.read_hdf(\"events_anomalydetection.h5\",stop=10000)\n",
    "print(df_test.shape)\n",
    "print(\"Memory in GB:\",sum(df_test.memory_usage(deep=True)) / (1024**3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d97f26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomaly",
   "language": "python",
   "name": "anomaly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
